{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM or HAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mantunes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/mantunes/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/mantunes/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import nltk\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('send us your password', 'spam'), ('review our website', 'spam'), ('send your password', 'spam'), ('send us your account', 'spam'), ('Your activity report', 'ham'), ('benefits physical activity', 'ham'), ('the importance vows', 'ham')]\n",
      "[('renew your password', 'spam'), ('renew your vows', 'spam'), ('benefits of our account', 'ham'), ('the importance of physical activity', 'ham')]\n"
     ]
    }
   ],
   "source": [
    "dataset_train = [\n",
    "('send us your password', 'spam'),\n",
    "('review our website', 'spam'),\n",
    "('send your password', 'spam'),\n",
    "('send us your account', 'spam'),\n",
    "('Your activity report', 'ham'),\n",
    "('benefits physical activity', 'ham'),\n",
    "('the importance vows', 'ham'),\n",
    "]\n",
    "\n",
    "dataset_test = [\n",
    "    ('renew your password', 'spam'),\n",
    "    ('renew your vows', 'spam'),\n",
    "    ('benefits of our account', 'ham'),\n",
    "    ('the importance of physical activity', 'ham')\n",
    "]\n",
    "\n",
    "print(f'{dataset_train}')\n",
    "print(f'{dataset_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB:\n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def _vocab(self, samples):\n",
    "        vocab = [token for sample in samples for token in sample]\n",
    "        #print(f'{samples}/{vocab}')\n",
    "        return list(set(vocab))\n",
    "\n",
    "    def _compute_likelihood(self, samples):\n",
    "        likelihood = {}\n",
    "        vocab = self._vocab(samples)\n",
    "        \n",
    "        for w in vocab:\n",
    "            count = 0\n",
    "            for sentence in samples:\n",
    "                if w in sentence:\n",
    "                    #print(w+\":\", sentence)\n",
    "                    count += 1\n",
    "            #print(f\"Number of ham emails with the word '{w}': {count}\")\n",
    "            #prob = (count + self.k)/(len(samples) + 2.0*self.k) # smoothing\n",
    "            #print(f\"Probability of the word '{w}': {prob} \")\n",
    "            likelihood[w.lower()] = count\n",
    "        return likelihood\n",
    "    \n",
    "    def _p_word_spam(self, token):\n",
    "        return (self.k + self.likelihood_spam.get(token, 0.0)) / ((2.0 * self.k) + self.num_spam_messages)\n",
    "\n",
    "    def _p_word_ham(self, token):\n",
    "        return (self.k + self.likelihood_ham.get(token, 0.0)) / ((2.0 * self.k) + self.num_ham_messages)\n",
    "\n",
    "    def train(self, dataset):\n",
    "        # compute priors\n",
    "        dataset_total = len(dataset)\n",
    "        spam_samples = [txt for txt, label in dataset if label == 'spam']\n",
    "        ham_samples = [txt for txt, label in dataset if label == 'ham']\n",
    "\n",
    "        #print(f'{spam_samples}')\n",
    "        #print(f'{ham_samples}')\n",
    "\n",
    "        self.ps = len(spam_samples) / dataset_total\n",
    "        self.ph = len(ham_samples) / dataset_total\n",
    "\n",
    "        #print(f'{self.ps} {self.ph}')\n",
    "\n",
    "        # Pre-process text\n",
    "        spam_samples = [nltk.word_tokenize(sample) for sample in spam_samples]\n",
    "        ham_samples = [nltk.word_tokenize(sample) for sample in ham_samples]\n",
    "\n",
    "        #print(f'{spam_samples}')\n",
    "        #print(f'{ham_samples}')\n",
    "\n",
    "        spam_samples = [[self.lemmatizer.lemmatize(w).lower() for w in tokens if len(self.lemmatizer.lemmatize(w)) > 2] for tokens in spam_samples]\n",
    "        ham_samples = [[self.lemmatizer.lemmatize(w).lower() for w in tokens if len(self.lemmatizer.lemmatize(w)) > 2] for tokens in ham_samples]\n",
    "        \n",
    "        #print(f'{spam_samples}')\n",
    "        #print(f'{ham_samples}')\n",
    "\n",
    "        # compute_likelihood\n",
    "        self.likelihood_spam = self._compute_likelihood(spam_samples)\n",
    "        self.num_spam_messages = len(spam_samples)\n",
    "        self.likelihood_ham = self._compute_likelihood(ham_samples)\n",
    "        self.num_ham_messages = len(ham_samples)\n",
    "\n",
    "        #print(f'{self.likelihood_spam}')\n",
    "        #print(f'{self.likelihood_ham}')\n",
    "    \n",
    "    def predict(self, txt):\n",
    "        # Pre-process text (similar to the train)\n",
    "        tokens = nltk.word_tokenize(txt)\n",
    "        tokens = [self.lemmatizer.lemmatize(w).lower() for w in tokens if len(self.lemmatizer.lemmatize(w)) > 2]\n",
    "\n",
    "        #print(tokens)\n",
    "\n",
    "        log_p_spam = 0.0\n",
    "        log_p_ham = 0.0\n",
    "\n",
    "        for t in tokens:\n",
    "            log_p_spam += math.log(self._p_word_spam(t))\n",
    "            log_p_ham += math.log(self._p_word_ham(t))\n",
    "        \n",
    "        prob_spam = (math.exp(log_p_spam)*self.ps)/(math.exp(log_p_spam)*self.ps+math.exp(log_p_ham)*self.ph)\n",
    "        if prob_spam >= 0.5:\n",
    "            return 'spam', prob_spam\n",
    "        else:\n",
    "            return 'ham', prob_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NB()\n",
    "clf.train(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send us your password -> spam 0.9487666034155597\n",
      "review our website -> spam 0.8605851979345954\n",
      "send your password -> spam 0.9487666034155597\n",
      "send us your account -> spam 0.9250693802035151\n",
      "Your activity report -> ham 0.204582651391162\n",
      "benefits physical activity -> ham 0.06041565973900433\n",
      "the importance vows -> ham 0.08796622097114705\n",
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "acc = 0.0\n",
    "for sentence, label in dataset_train:\n",
    "    predicted_label, prob_spam = clf.predict(sentence)\n",
    "    print(f'{sentence} -> {predicted_label} {prob_spam}')\n",
    "    if label == predicted_label:\n",
    "        acc += 1.0\n",
    "print(f'Accuracy = {acc/len(dataset_train)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renew your password -> spam 0.8223684210526315\n",
      "renew your vows -> ham 0.43554006968641107\n",
      "benefits of our account -> spam 0.6067961165048542\n",
      "the importance of physical activity -> ham 0.026092764998121326\n",
      "Accuracy = 0.5\n"
     ]
    }
   ],
   "source": [
    "acc = 0.0\n",
    "for sentence, label in dataset_test:\n",
    "    predicted_label, prob_spam = clf.predict(sentence)\n",
    "    print(f'{sentence} -> {predicted_label} {prob_spam}')\n",
    "    if label == predicted_label:\n",
    "        acc += 1.0\n",
    "print(f'Accuracy = {acc/len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_521, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Target</th><th>SMS</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;ham&quot;</td><td>&quot;Go until juron…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Ok lar... Joki…</td></tr><tr><td>&quot;spam&quot;</td><td>&quot;Free entry in …</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;U dun say so e…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Nah I don&#x27;t th…</td></tr><tr><td>&quot;spam&quot;</td><td>&quot;FreeMsg Hey th…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Even my brothe…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;As per your re…</td></tr><tr><td>&quot;spam&quot;</td><td>&quot;WINNER!! As a …</td></tr><tr><td>&quot;spam&quot;</td><td>&quot;Had your mobil…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;I&#x27;m gonna be h…</td></tr><tr><td>&quot;spam&quot;</td><td>&quot;SIX chances to…</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Anything lor. …</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Get me out of …</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Ok lor... Sony…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Ard 6 like dat…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Why don&#x27;t you …</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Huh y lei...&quot;</td></tr><tr><td>&quot;spam&quot;</td><td>&quot;REMINDER FROM …</td></tr><tr><td>&quot;spam&quot;</td><td>&quot;This is the 2n…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Will �_ b goin…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Pity, * was in…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;The guy did so…</td></tr><tr><td>&quot;ham&quot;</td><td>&quot;Rofl. Its true…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_521, 2)\n",
       "┌────────┬───────────────────────────────────┐\n",
       "│ Target ┆ SMS                               │\n",
       "│ ---    ┆ ---                               │\n",
       "│ str    ┆ str                               │\n",
       "╞════════╪═══════════════════════════════════╡\n",
       "│ ham    ┆ Go until jurong point, crazy.. A… │\n",
       "│ ham    ┆ Ok lar... Joking wif u oni...     │\n",
       "│ spam   ┆ Free entry in 2 a wkly comp to w… │\n",
       "│ ham    ┆ U dun say so early hor... U c al… │\n",
       "│ …      ┆ …                                 │\n",
       "│ ham    ┆ Will �_ b going to esplanade fr … │\n",
       "│ ham    ┆ Pity, * was in mood for that. So… │\n",
       "│ ham    ┆ The guy did some bitching but I … │\n",
       "│ ham    ┆ Rofl. Its true to its name        │\n",
       "└────────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv('../datasets/spam.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.rows()\n",
    "dataset = [(text, label) for (label, text) in dataset]\n",
    "idx = int(len(dataset)*.8)\n",
    "dataset_train = dataset[0: idx]\n",
    "dataset_test = dataset[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NB()\n",
    "clf.train(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8265398550724637\n"
     ]
    }
   ],
   "source": [
    "acc = 0.0\n",
    "for sentence, label in dataset_train:\n",
    "    predicted_label, prob_spam = clf.predict(sentence)\n",
    "    #print(f'{sentence} -> {predicted_label} {prob_spam}')\n",
    "    if label == predicted_label:\n",
    "        acc += 1.0\n",
    "print(f'Accuracy = {acc/len(dataset_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7457013574660634\n"
     ]
    }
   ],
   "source": [
    "acc = 0.0\n",
    "for sentence, label in dataset_test:\n",
    "    predicted_label, prob_spam = clf.predict(sentence)\n",
    "    #print(f'{sentence} -> {predicted_label} {prob_spam}')\n",
    "    if label == predicted_label:\n",
    "        acc += 1.0\n",
    "print(f'Accuracy = {acc/len(dataset_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
